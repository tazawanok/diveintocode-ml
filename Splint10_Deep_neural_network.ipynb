{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/naoki/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) \n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=20)\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    mini_X_train, mini_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "\n",
    "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        \n",
    "        self.h_w = None\n",
    "        self.h_b = None\n",
    "        \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, X,):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"   \n",
    "        self.Z = X \n",
    "        self.A = self.Z @ self.W + self.B\n",
    "\n",
    "        return self.A\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.Z.T @ dA\n",
    "        dZ = dA @ self.W.T\n",
    "        \n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        np.random.seed(5)\n",
    "        self.W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return self.W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        np.random.seed(5)\n",
    "        self.B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return self.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self,layer):  #layer,\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        layer.W -= (self.lr * layer.dW)\n",
    "        layer.B -= (self.lr * layer.dB)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fnk(target,pred):\n",
    "    Loss = - np.sum(target * np.log(pred)) / target.shape[0]\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class soft_max:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.soft_max = 0\n",
    "    \n",
    "    def forward(self,data):\n",
    "        \n",
    "        if data.ndim == 2:\n",
    "            data = data.T\n",
    "            data = data - np.max(data, axis=0)\n",
    "            self.soft_max = np.exp(data) / np.sum(np.exp(data), axis=0)\n",
    "            return self.soft_max.T\n",
    "        data = data - np.max(data)   # オーバーフロー対策\n",
    "        self.soft_max = np.exp(data) / np.sum(np.exp(data))\n",
    "        return self.soft_max\n",
    "\n",
    "    def backward(self, target):\n",
    "        self.dA = self.soft_max.T - target\n",
    "        return self.dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. ... 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(edgeitems=10)\n",
    "#print(np.unique(X_train))\n",
    "sf = soft_max()\n",
    "a = sf.forward(X_train)\n",
    "print(np.sum(a,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigmoid:\n",
    "    \n",
    "    \n",
    "    def forward(self,data):\n",
    "        C = np.max(data)\n",
    "        self.sig = 1 / (1 + np.exp(-data/C))\n",
    "        return self.sig\n",
    "    \n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        self.sig_d = dZ * (1 - self.sig) * self.sig\n",
    "        return self.sig_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tanh:\n",
    "    \n",
    "    \n",
    "    def forward(self,data):\n",
    "        C = np.max(data)\n",
    "        self.t = np.tanh(data/C)\n",
    "        return self.t\n",
    "    \n",
    "    \n",
    "    def backward(self,A,dZ):\n",
    "        C = np.max(A)\n",
    "        B = A/C\n",
    "        self.dA2 = dZ*(1-np.tanh(B))\n",
    "        return self.dA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "ReLUは以下の数式です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        self.A = x.copy()\n",
    "        self.A[self.mask] = 0\n",
    "        return self.A\n",
    "        \n",
    "    def backward(self, dA):\n",
    "        dA[self.mask] = 0\n",
    "        dA = dA\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \n",
    "    \n",
    "    def W(self, n_node1, n_node2):\n",
    "        self.sigma = (1 / np.sqrt(n_node1))\n",
    "        np.random.seed(0)\n",
    "        self.W = self.sigma * np.random.randn(n_node1, n_node2)\n",
    "        return self.W\n",
    "        \n",
    "    def B(self,n_node2):\n",
    "        np.random.seed(0)\n",
    "        self.B = self.sigma * np.random.randn(n_node2)\n",
    "        return self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class He:\n",
    "    \n",
    "    def W(self,  n_node1, n_node2):\n",
    "        sigma = np.sqrt(2 / n_node1)\n",
    "        np.random.seed(0)\n",
    "        self.W = sigma * np.random.randn(n_node1, n_node2)\n",
    "        return self.W\n",
    "        \n",
    "    def B(self,n_node2):\n",
    "        sigma = np.sqrt(2 / n_node2)\n",
    "        np.random.seed(0)\n",
    "        self.B = sigma * np.random.randn(n_node2)\n",
    "        return self.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self , lr , b_size):\n",
    "        self.lr = lr\n",
    "        self.b_size = b_size\n",
    "    \n",
    "    def update(self , layer):        \n",
    "        layer.h_w += (layer.dW/self.b_size) * (layer.dW/self.b_size)\n",
    "        layer.W -= self.lr * (layer.dW/self.b_size) / (np.sqrt(layer.h_w) + 1e-7)\n",
    "        layer.h_b += (layer.dB/self.b_size) * (layer.dB/self.b_size)\n",
    "        layer.B -= self.lr * (layer.dB/self.b_size) / (np.sqrt(layer.hb) + 1e-7)\n",
    "        self.h_w = layer.h_w\n",
    "        self.h_b = layer.h_b\n",
    "        return layer.W, layer.B\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleDNN():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 batch_size=20, \n",
    "                 epoch=20, \n",
    "                 FC1 = FC(784,600,initializer=He(),optimizer=SGD(lr=0.01)),\n",
    "                 FC2=FC(600,600,initializer=He(),optimizer=SGD(lr=0.01)),\n",
    "                 FC3=FC(600,10,initializer=He(),optimizer=SGD(lr=0.01)),\n",
    "                 activation1 = ReLU(),\n",
    "                 activation2 = ReLU(),\n",
    "                 activation_end = soft_max(),\n",
    "                 verbose = True):\n",
    "        \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.Loss = 0\n",
    "        self.epoch = epoch\n",
    "        self.FC1 = FC1\n",
    "        self.FC2 = FC2\n",
    "        self.FC3 = FC3\n",
    "        self.activation1 = activation1\n",
    "        self.activation2 = activation2\n",
    "        self.activation3 = activation_end\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, data, target, test, target2):\n",
    "        self.loss_list = []\n",
    "        for i in range(self.epoch):\n",
    "            print(i,\"epoch\")\n",
    "            get_mini_batch = GetMiniBatch(data, target, batch_size=self.batch_size)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.A1 = self.FC1.forward(mini_X_train)\n",
    "                self.Z1 = self.activation1.forward(self.A1)\n",
    "\n",
    "                self.A2 = self.FC2.forward(self.Z1)\n",
    "                self.Z2 = self.activation2.forward(self.A2)\n",
    "\n",
    "                self.A3 = self.FC3.forward(self.Z2)\n",
    "                self.Z3 = self.activation3.forward(self.A3)\n",
    "    \n",
    "                self.A3_b = self.activation3.backward(mini_y_train)\n",
    "                self.Z3_b = self.FC3.backward(self.A3_b)\n",
    "                \n",
    "                self.Z2_b = self.activation2.backward(self.Z3_b)\n",
    "                self.A2_b = self.FC2.backward(self.Z2_b)\n",
    "                \n",
    "                self.Z1_b = self.activation1.backward(self.A2_b)\n",
    "                self.A1_b = self.FC1.backward(self.Z1_b)\n",
    "                \n",
    "            \n",
    "        \n",
    "            A1 = self.FC1.forward(test)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            print(\"Z3_max\",np.argmax(Z3,axis=1))\n",
    "            loss= loss_fnk(target2, Z3)\n",
    "            self.loss_list.append(loss)\n",
    "            \n",
    "            \n",
    "    def predict(self, data):\n",
    "        \n",
    "        A1 = self.FC1.forward(data)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        y_pred = np.argmax(Z3,axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "1 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "2 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "3 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "4 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "5 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "6 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "7 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "8 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "9 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "10 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "11 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "12 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "13 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n",
      "14 epoch\n",
      "Z3_max [7 2 1 0 4 1 4 9 5 9 ... 7 8 9 0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "DNN = ScratchSimpleDNN(epoch=15)\n",
    "DNN.fit(X_train, y_train_one_hot, X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08382586585881006,\n",
       " 0.10004077043804427,\n",
       " 0.07786942825435961,\n",
       " 0.07752536576149865,\n",
       " 0.07518584192088174,\n",
       " 0.0777617234330528,\n",
       " 0.07533857569810236,\n",
       " 0.0748041765085403,\n",
       " 0.07602694583691388,\n",
       " 0.07657278905915864,\n",
       " 0.07705913128581315,\n",
       " 0.07751895155617365,\n",
       " 0.07793732659637576,\n",
       " 0.07831261797880486,\n",
       " 0.07866766656096891]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN.loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8b10021250>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(len(DNN.loss_list)), DNN.loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, ..., 7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prad = DNN.predict(X_test)\n",
    "# a = np.argmax(a,axis=1)\n",
    "y_true = np.argmax(y_test_one_hot,axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true,y_prad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, ..., 9, 2, 9, 5, 1, 8, 3, 5, 6, 8],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer=SimpleInitializer(sigma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "447px",
    "left": "1325px",
    "right": "20px",
    "top": "120px",
    "width": "335px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
