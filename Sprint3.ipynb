{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    ")\n",
    "=\n",
    "θ\n",
    "0\n",
    "x\n",
    "0\n",
    "+\n",
    "θ\n",
    "1\n",
    "x\n",
    "1\n",
    "+\n",
    ".\n",
    ".\n",
    ".\n",
    "+\n",
    "θ\n",
    "j\n",
    "x\n",
    "j\n",
    "+\n",
    ".\n",
    ".\n",
    ".\n",
    "+\n",
    "θ\n",
    "n\n",
    "x\n",
    "n\n",
    ".\n",
    "(\n",
    "x\n",
    "0\n",
    "=\n",
    "1\n",
    ")\n",
    "x\n",
    " : 特徴量ベクトル\n",
    "\n",
    "θ\n",
    " : パラメータベクトル\n",
    "\n",
    "n\n",
    " : 特徴量の数\n",
    "\n",
    "x\n",
    "j\n",
    " : j番目の特徴量\n",
    "\n",
    "θ\n",
    "j\n",
    " : j番目のパラメータ（重み）\n",
    "\n",
    "特徴量の数\n",
    "n\n",
    "は任意の値に対応できる実装にしてください。\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "#     randint(0,1,(X.shape[0]+1,5))\n",
    "    a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "    X = np.hstack([a ,X])\n",
    "    self.Theta = np.random.random_sample((X.shape[1]+1, 1))\n",
    "    self.y_ = self.Theta @ X.T\n",
    "    return self.y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_hypothesis(X):\n",
    "    a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "    X = np.hstack([a ,X])\n",
    "    Theta = np.random.random_sample((1,X.shape[1]))\n",
    "    y = Theta @ X.T\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "θ\n",
    "j\n",
    ":=\n",
    "θ\n",
    "j\n",
    "−\n",
    "α\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "[\n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    "j\n",
    "]\n",
    "α\n",
    " : 学習率\n",
    "\n",
    "i\n",
    " : サンプルのインデックス\n",
    "\n",
    "j\n",
    " : 特徴量のインデックス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_error(self, y):\n",
    "    self.error = self.y_ - y\n",
    "    self.error = self.error.T\n",
    "    return self.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_hypothesis(X):\n",
    "    a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "    X = np.hstack([a ,X])\n",
    "    Theta = np.random.random_sample((1,X.shape[1]))\n",
    "    y = Theta @ X.T\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(y):\n",
    "    y_n = linear_hypothesis(X)\n",
    "    error = y_n - y\n",
    "    error = error.T\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X):\n",
    "    Theta = Theta - 0.01 * (error.T * X).sum() / x.shape[0]\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33049545, -0.17249613,  0.12435621, -0.14154832]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = get_error(y)\n",
    "Theta = np.random.random_sample((1,X.shape[1]))\n",
    "Theta = Theta - 0.01 * (error * X).sum() / X.shape[0]\n",
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = get_error(y)\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(self, X, error):\n",
    "    \"\"\"\n",
    "    パラメータの更新式\n",
    "    学習率を0.01として作成\n",
    "    \"\"\"\n",
    "#     self.Theta = self.Theta - 0.01 * ((self.y_ - y) * X.T).sum() / x.shape[0]\n",
    "    self.Theta = self.Theta - 0.01 * ((self.error * X).sum()) / x.shape[0]\n",
    "    return self.Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "仮定関数 \n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    ")\n",
    " の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "    pred_y = X @ self.Theta\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "L\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    ")\n",
    " : 仮定関数\n",
    "\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13481066, 0.42480934, 0.7430156 , 0.99975703]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1,X.shape[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    \n",
    "    def _first(self, X):\n",
    "        random.seed(1)\n",
    "        if self.bias == True:\n",
    "            a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "            X = np.hstack([a ,X])\n",
    "        self.Theta = np.random.rand(1,X.shape[1])  \n",
    "        \n",
    "    def _linear_hypothesis(self, X): \n",
    "        if self.bias == True:\n",
    "            a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "            X = np.hstack([a ,X])\n",
    "        self.y_ = self.Theta @ X.T\n",
    "        return self.y_\n",
    "\n",
    "\n",
    "    def _get_error(self, y):\n",
    "        self.error = self.y_ - y\n",
    "        self.error = self.error.T\n",
    "        return self.error\n",
    "    \n",
    "    \n",
    "    def _gradient_descent(self, X):\n",
    "        if self.bias == True:\n",
    "            a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "            X = np.hstack([a ,X])\n",
    "        self.Theta = self.Theta - self.lr * ((self.error * X).sum()) / X.shape[0]\n",
    "        return self.Theta\n",
    "\n",
    "    \n",
    "    def pred(self, X):\n",
    "        if self.bias == True:\n",
    "            a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "            X = np.hstack([a ,X])\n",
    "        self.y_ = self.Theta @ X.T\n",
    "        return self.y_\n",
    "    \n",
    "    \n",
    "    def _loss_fnk(self, y):\n",
    "        F = ((self.error**2).sum()) / (2*X.shape[0])\n",
    "        return self.loss_f\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        self._first(X)\n",
    "\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            self._linear_hypothesis(X)\n",
    "            self._get_error(y)\n",
    "            self._gradient_descent(X)\n",
    "            self.pred(X)\n",
    "            self.loss[i] = self._loss_fnk(y)\n",
    "            if (X_val is not None) and (y_val is not None):\n",
    "                self._linear_hypothesis(X_val)\n",
    "                self.pred(X_val)\n",
    "                self._get_error(y_val)\n",
    "                self.val_loss[i] = self._loss_fnk(y_val)\n",
    "                if self._loss_fnk(y) == 0:\n",
    "                    break\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.verbose:\n",
    "            print(self.loss)\n",
    "            print(self.val_loss)\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         pass\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        if self.bias:\n",
    "            a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "            X = np.hstack([a ,X])\n",
    "#         print(self.Theta.shape)\n",
    "#         print(X.shape)\n",
    "        self.pred = self.Theta @ X.T\n",
    "        return self.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.56921177 6.27786921 5.99980008 5.73439964 5.48109071 5.23932242\n",
      " 5.00856897 4.78832854 4.57812216 4.37749267 4.18600377 4.00323901\n",
      " 3.82880092 3.66231015 3.50340461 3.35173874 3.20698269 3.06882165\n",
      " 2.93695516 2.81109645 2.6909718  2.57631997 2.46689162 2.36244877\n",
      " 2.26276429 2.16762138 2.07681314 1.99014208 1.90741971 1.82846613\n",
      " 1.75310964 1.68118635 1.61253986 1.54702086 1.48448688 1.42480192\n",
      " 1.36783617 1.31346575 1.26157243 1.21204334 1.16477077 1.11965192\n",
      " 1.07658866 1.03548734 0.99625857 0.95881705 0.92308135 0.88897375\n",
      " 0.85642007 0.82534953 0.79569454 0.76739062 0.74037621 0.71459257\n",
      " 0.68998362 0.66649583 0.64407814 0.62268179 0.60226025 0.5827691\n",
      " 0.56416596 0.54641037 0.52946372 0.51328914 0.49785148 0.48311714\n",
      " 0.4690541  0.45563176 0.44282093 0.43059376 0.41892366 0.40778523\n",
      " 0.39715427 0.38700765 0.37732331 0.36808018 0.35925816 0.35083807\n",
      " 0.3428016  0.33513126 0.32781038 0.32082303 0.31415403 0.30778886\n",
      " 0.30171369 0.29591529 0.29038107 0.28509899 0.28005755 0.2752458\n",
      " 0.27065328 0.26626998 0.26208639 0.25809339 0.25428232 0.25064488\n",
      " 0.24717316 0.2438596  0.24069702 0.23767851 0.23479753 0.23204781\n",
      " 0.22942336 0.22691848 0.22452772 0.22224588 0.220068   0.21798935\n",
      " 0.2160054  0.21411183 0.21230454 0.21057958 0.20893322 0.20736186\n",
      " 0.20586209 0.20443065 0.20306442 0.20176044 0.20051587 0.199328\n",
      " 0.19819425 0.19711216 0.19607936 0.19509362 0.19415278 0.19325481\n",
      " 0.19239775 0.19157974 0.190799   0.19005383 0.1893426  0.18866378\n",
      " 0.18801589 0.18739751 0.18680731 0.186244   0.18570635 0.18519319\n",
      " 0.18470342 0.18423596 0.18378979 0.18336395 0.18295752 0.1825696\n",
      " 0.18219935 0.18184598 0.1815087  0.18118679 0.18087954 0.18058629\n",
      " 0.18030641 0.18003927 0.17978431 0.17954096 0.1793087  0.17908701\n",
      " 0.17887543 0.17867349 0.17848075 0.17829679 0.17812121 0.17795363\n",
      " 0.17779369 0.17764103 0.17749533 0.17735627 0.17722354 0.17709686\n",
      " 0.17697595 0.17686054 0.1767504  0.17664527 0.17654494 0.17644917\n",
      " 0.17635777 0.17627053 0.17618727 0.1761078  0.17603195 0.17595956\n",
      " 0.17589046 0.17582451 0.17576157 0.1757015  0.17564416 0.17558943\n",
      " 0.1755372  0.17548735 0.17543977 0.17539435 0.17535101 0.17530964\n",
      " 0.17527015 0.17523247 0.1751965  0.17516217 0.1751294  0.17509812\n",
      " 0.17506828 0.17503979 0.1750126  0.17498664 0.17496187 0.17493823\n",
      " 0.17491567 0.17489413 0.17487358 0.17485396 0.17483523 0.17481736\n",
      " 0.1748003  0.17478402 0.17476849 0.17475365 0.1747395  0.17472599\n",
      " 0.1747131  0.17470079 0.17468904 0.17467783 0.17466713 0.17465692\n",
      " 0.17464717 0.17463787 0.17462899 0.17462051 0.17461242 0.1746047\n",
      " 0.17459733 0.1745903  0.17458359 0.17457718 0.17457107 0.17456523\n",
      " 0.17455966 0.17455434 0.17454927 0.17454442 0.1745398  0.17453539\n",
      " 0.17453118 0.17452716 0.17452332 0.17451966 0.17451617 0.17451283\n",
      " 0.17450965 0.17450661 0.17450371 0.17450094 0.1744983  0.17449578\n",
      " 0.17449337 0.17449108 0.17448889 0.17448679 0.1744848  0.17448289\n",
      " 0.17448107 0.17447934 0.17447768 0.1744761  0.17447459 0.17447315\n",
      " 0.17447177 0.17447046 0.17446921 0.17446801 0.17446687 0.17446578\n",
      " 0.17446474 0.17446375 0.1744628  0.1744619  0.17446103 0.17446021\n",
      " 0.17445943 0.17445868 0.17445796 0.17445728 0.17445662 0.174456\n",
      " 0.17445541 0.17445484 0.1744543  0.17445378 0.17445329 0.17445282\n",
      " 0.17445237 0.17445194 0.17445153 0.17445114 0.17445077 0.17445041\n",
      " 0.17445007 0.17444975 0.17444944 0.17444915 0.17444886 0.1744486\n",
      " 0.17444834 0.17444809 0.17444786 0.17444764 0.17444742 0.17444722\n",
      " 0.17444703 0.17444684 0.17444666 0.1744465  0.17444634 0.17444618\n",
      " 0.17444603 0.17444589 0.17444576 0.17444563 0.17444551 0.1744454\n",
      " 0.17444529 0.17444518 0.17444508 0.17444498 0.17444489 0.1744448\n",
      " 0.17444472 0.17444464 0.17444456 0.17444449 0.17444442 0.17444435\n",
      " 0.17444429 0.17444423 0.17444417 0.17444412 0.17444406 0.17444401\n",
      " 0.17444397 0.17444392 0.17444388 0.17444383 0.1744438  0.17444376\n",
      " 0.17444372 0.17444369 0.17444365 0.17444362 0.17444359 0.17444356\n",
      " 0.17444354 0.17444351 0.17444348 0.17444346 0.17444344 0.17444342\n",
      " 0.1744434  0.17444338 0.17444336 0.17444334 0.17444332 0.17444331\n",
      " 0.17444329 0.17444328 0.17444326 0.17444325 0.17444323 0.17444322\n",
      " 0.17444321 0.1744432  0.17444319 0.17444318 0.17444317 0.17444316\n",
      " 0.17444315 0.17444314 0.17444313 0.17444313 0.17444312 0.17444311\n",
      " 0.1744431  0.1744431  0.17444309 0.17444309 0.17444308 0.17444307\n",
      " 0.17444307 0.17444306 0.17444306 0.17444306 0.17444305 0.17444305\n",
      " 0.17444304 0.17444304 0.17444304 0.17444303 0.17444303 0.17444303\n",
      " 0.17444302 0.17444302 0.17444302 0.17444302 0.17444301 0.17444301\n",
      " 0.17444301 0.17444301 0.174443   0.174443   0.174443   0.174443\n",
      " 0.174443   0.174443   0.17444299 0.17444299 0.17444299 0.17444299\n",
      " 0.17444299 0.17444299 0.17444299 0.17444299 0.17444298 0.17444298\n",
      " 0.17444298 0.17444298 0.17444298 0.17444298 0.17444298 0.17444298\n",
      " 0.17444298 0.17444298 0.17444298 0.17444298 0.17444298 0.17444297\n",
      " 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297\n",
      " 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297\n",
      " 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297\n",
      " 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297\n",
      " 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297 0.17444297\n",
      " 0.17444297 0.17444297 0.17444297 0.17444297 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296 0.17444296\n",
      " 0.17444296 0.17444296 0.17444296 0.17444296]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.78995449, 0.67973351, 0.73173493, 0.74425556, 0.82337727,\n",
       "        0.93814616, 0.81872759, 0.78763097, 0.69507609, 0.70644235,\n",
       "        0.83100639, 0.81873024, 0.67443055, 0.67053593, 0.82984938,\n",
       "        1.01055129, 0.87876958, 0.80338501, 0.87503773, 0.89411481,\n",
       "        0.78480902, 0.88225011, 0.79651094, 0.82418803, 0.86326267,\n",
       "        0.70129423, 0.82933615, 0.79667107, 0.75653171, 0.77626736,\n",
       "        0.74284458, 0.78198176, 0.93501188, 0.93451079, 0.71987287,\n",
       "        0.6925081 , 0.7426001 , 0.81807432, 0.70552717, 0.77950341,\n",
       "        0.79666842, 0.53376357, 0.75611761, 0.88149241, 0.96692191,\n",
       "        0.70129158, 0.89552844, 0.75470663, 0.83913395, 0.74749161,\n",
       "        1.21066811, 1.24317571, 1.23661925, 0.98758501, 1.1487114 ,\n",
       "        1.17202672, 1.31971729, 0.91744505, 1.13901803, 1.11173496,\n",
       "        0.83782489, 1.18869064, 0.88136043, 1.2079305 , 1.0718522 ,\n",
       "        1.16522314, 1.25760575, 1.03893581, 1.00647861, 0.98834272,\n",
       "        1.3686375 , 1.06529575, 1.13361329, 1.15577424, 1.11074072,\n",
       "        1.14805548, 1.14058649, 1.26928433, 1.19980029, 0.93270328,\n",
       "        0.95633091, 0.92805625, 1.03610855, 1.25170522, 1.27386088,\n",
       "        1.33970691, 1.22318609, 0.9819411 , 1.17136815, 1.03817546,\n",
       "        1.10941674, 1.21838157, 1.02565748, 0.88402226, 1.11032662,\n",
       "        1.16465421, 1.15278951, 1.12699584, 0.89538323, 1.11265014,\n",
       "        1.63356582, 1.3082519 , 1.42409345, 1.37899474, 1.47144519,\n",
       "        1.48736465, 1.21488361, 1.40162813, 1.27499189, 1.65114757,\n",
       "        1.39126559, 1.28917482, 1.38909956, 1.26437539, 1.4006997 ,\n",
       "        1.46937299, 1.37319069, 1.70987352, 1.44944966, 1.09695446,\n",
       "        1.48811176, 1.33354447, 1.43006027, 1.22449529, 1.50280107,\n",
       "        1.44110892, 1.24307392, 1.31663607, 1.3858635 , 1.33396916,\n",
       "        1.35194757, 1.62222493, 1.39929402, 1.23918724, 1.26564213,\n",
       "        1.4318774 , 1.58605394, 1.40661347, 1.30991949, 1.39142307,\n",
       "        1.47765803, 1.37375167, 1.3082519 , 1.52592761, 1.55652314,\n",
       "        1.37955572, 1.2021795 , 1.35551929, 1.5510627 , 1.36257948]])"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc = ScratchLinearRegression(num_iter=1000, lr=0.0001, bias=True, verbose=True)\n",
    "Sc.fit(X, y)\n",
    "Sc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Sc.predict(X_train)\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    mse = ((y_pred - y) ** 2).sum() / X.shape[0]\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24305012797044995"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "目的関数（損失関数） \n",
    "J\n",
    "(\n",
    "θ\n",
    ")\n",
    " は次の式です。\n",
    "\n",
    "J\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "2\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    ")\n",
    " : 仮定関数\n",
    "\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.79475756 27.63164003 26.51605548 ...  0.33361654  0.33361654\n",
      "  0.33361654]\n",
      "[11.42400139 10.97261089 10.53946948 ...  0.14415549  0.14415549\n",
      "  0.14415549]\n"
     ]
    }
   ],
   "source": [
    "Sc = ScratchLinearRegression(num_iter=2000, lr=0.0001, bias=False, verbose=True)\n",
    "Sc.fit(X = X_train, y = y_train, X_val=X_test, y_val=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.79475756, 27.63164003, 26.51605548, 25.44606136, 24.41979454,\n",
       "       23.43546803, 22.49136786, 21.58585009, 20.717338  , 19.88431927,\n",
       "       19.0853434 , 18.31901917, 17.5840122 , 16.87904266, 16.20288302,\n",
       "       15.5543559 , 14.93233204, 14.33572835, 13.76350598, 13.21466854])"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.loss[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.42400139, 10.97261089, 10.53946948, 10.12383546,  9.72499736,\n",
       "        9.3422727 ,  8.97500681,  8.6225717 ,  8.28436496,  7.95980872,\n",
       "        7.64834866,  7.34945304,  7.06261178,  6.78733556,  6.523155  ,\n",
       "        6.26961984,  6.02629816,  5.7927756 ,  5.56865469,  5.35355415])"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.val_loss[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbda1460b70>"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(2000), Sc.loss, linewidth=4, color=\"red\", label=\"loss\")\n",
    "plt.plot(range(2000), Sc.val_loss, linewidth=4, color=\"blue\", label=\"val_loss\")\n",
    "plt.ylabel(\"loss_fnc\")\n",
    "plt.xlabel(\"lr\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74817189, 1.2674677 , 1.62552509, 1.39047161, 1.43002089,\n",
       "        0.91537637, 1.38830728, 1.33998364, 1.37209056, 1.2312253 ,\n",
       "        1.246729  , 1.28077791, 1.31150268, 1.25691954, 1.2366686 ,\n",
       "        1.47274805, 1.16222552, 1.14886887, 1.2909915 , 1.47562538,\n",
       "        0.8713638 , 1.09313513, 1.41025157, 1.2407699 , 1.07550756,\n",
       "        1.34709771, 1.4336059 , 1.27967374, 1.03951588, 1.34806096,\n",
       "        1.1900096 , 1.05240718, 1.48311433, 1.08511424, 0.98375359,\n",
       "        0.98674459, 1.58891022, 1.12533267, 1.13850808, 1.18900217,\n",
       "        1.12830062, 1.33371866, 1.05287188, 1.27322688, 1.54857328]])"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "housing = pd.read_csv(\"/Users/naoki/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_int = housing\n",
    "list_str = []\n",
    "for i in housing.columns:\n",
    "    if housing[i].dtypes == \"O\":\n",
    "        housing_int = housing_int.drop(i,axis=1)\n",
    "        list_str.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "MSSubClass       0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "MasVnrArea       0\n",
       "BsmtFinSF1       0\n",
       "BsmtFinSF2       0\n",
       "BsmtUnfSF        0\n",
       "TotalBsmtSF      0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "LowQualFinSF     0\n",
       "GrLivArea        0\n",
       "BsmtFullBath     0\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "TotRmsAbvGrd     0\n",
       "Fireplaces       0\n",
       "GarageYrBlt      0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "3SsnPorch        0\n",
       "ScreenPorch      0\n",
       "PoolArea         0\n",
       "MiscVal          0\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SalePrice        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_int = housing_int.fillna(0)\n",
    "housing_int.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_str = housing[list_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_str = pd.get_dummies(housing_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning_C (all)</th>\n",
       "      <th>MSZoning_FV</th>\n",
       "      <th>MSZoning_RH</th>\n",
       "      <th>MSZoning_RL</th>\n",
       "      <th>MSZoning_RM</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "      <th>Alley_Grvl</th>\n",
       "      <th>Alley_Pave</th>\n",
       "      <th>LotShape_IR1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning_C (all)  MSZoning_FV  MSZoning_RH  MSZoning_RL  MSZoning_RM  \\\n",
       "0                 0            0            0            1            0   \n",
       "1                 0            0            0            1            0   \n",
       "2                 0            0            0            1            0   \n",
       "3                 0            0            0            1            0   \n",
       "4                 0            0            0            1            0   \n",
       "\n",
       "   Street_Grvl  Street_Pave  Alley_Grvl  Alley_Pave  LotShape_IR1  \\\n",
       "0            0            1           0           0             0   \n",
       "1            0            1           0           0             0   \n",
       "2            0            1           0           0             1   \n",
       "3            0            1           0           0             1   \n",
       "4            0            1           0           0             1   \n",
       "\n",
       "           ...            SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "0          ...                         0             0             0   \n",
       "1          ...                         0             0             0   \n",
       "2          ...                         0             0             0   \n",
       "3          ...                         0             0             0   \n",
       "4          ...                         0             0             0   \n",
       "\n",
       "   SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0            1                      0                      0   \n",
       "1            1                      0                      0   \n",
       "2            1                      0                      0   \n",
       "3            1                      1                      0   \n",
       "4            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1          ...            \\\n",
       "0          2003       196.0         706          ...             \n",
       "1          1976         0.0         978          ...             \n",
       "2          2002       162.0         486          ...             \n",
       "3          1970         0.0         216          ...             \n",
       "4          2000       350.0         655          ...             \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "\n",
       "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      1                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     0                      0  \n",
       "4                     0                     1                      0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 1037,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_new = pd.concat([housing_int, housing_str], axis=1)\n",
    "housing_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_new.drop([\"SalePrice\", \"Id\"], axis = 1)\n",
    "# X = X.loc[:,[\"YrSold\",\"LotArea\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 288)"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log1p(X)\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460,)"
      ]
     },
     "execution_count": 1042,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = housing_new[\"SalePrice\"]\n",
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    " \n",
    "# 標準化\n",
    "# sc = StandardScaler()\n",
    "# X_train_std = sc.fit_transform(X_train)\n",
    "# X_test_std = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.45675794e+10 1.41014595e+10 1.36524080e+10 ... 1.83832114e+09\n",
      " 1.83832114e+09 1.83832114e+09]\n",
      "[4.78352763e+09 4.63361803e+09 4.48917512e+09 ... 6.56085329e+08\n",
      " 6.56085329e+08 6.56085329e+08]\n"
     ]
    }
   ],
   "source": [
    "Sc = ScratchLinearRegression(num_iter=2000, lr=0.000001, bias=True, verbose=True)\n",
    "Sc.fit(X = X_train, y = y_train, X_val=X_test, y_val=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.78352763e+09, 4.63361803e+09, 4.48917512e+09, ...,\n",
       "       6.56085329e+08, 6.56085329e+08, 6.56085329e+08])"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[181308.86755389, 193498.82376162, 186020.97883583,\n",
       "        207407.58970599, 173806.15898805, 186592.15085176,\n",
       "        195321.22114951, 187695.48379438, 220193.10672017,\n",
       "        176778.53767433, 174346.69821425, 170078.39062743,\n",
       "        187077.155424  , 185859.77970487, 184199.91509341,\n",
       "        177913.93339852, 196738.73431519, 145682.49105212,\n",
       "        163440.93852969, 182123.66343741, 180713.85178391,\n",
       "        178411.8854156 , 175803.86094836, 178355.92536785,\n",
       "        198532.01090543, 194535.67335622, 185887.3922585 ,\n",
       "        141836.60825888, 199061.36734669, 190142.96065927,\n",
       "        181909.19270891, 211126.1079217 , 173995.65163076,\n",
       "        211519.3900166 , 193792.37575025, 195211.30554879,\n",
       "        197970.56900876, 181347.5194373 , 193193.76798703,\n",
       "        210039.22642496, 187921.722145  , 168478.80823826,\n",
       "        170203.65505704, 197516.54497895, 215164.6371855 ,\n",
       "        189256.579344  , 180805.64863637, 175780.26427691,\n",
       "        203919.24891822, 136305.15349979, 208338.09328668,\n",
       "        178825.3487618 , 186414.66514375, 139808.6547941 ,\n",
       "        186267.0985596 , 161993.85753117, 184540.71349653,\n",
       "        184842.72529725, 177916.59779847, 169594.48106442,\n",
       "        186068.98148467, 187128.26728096, 178460.02699819,\n",
       "        181830.40793521, 195760.8316241 , 196055.45972859,\n",
       "        181710.0729505 , 189305.11549442, 186428.02057745,\n",
       "        183105.22253508, 194443.92021122, 172931.48664274,\n",
       "        136702.79521772, 182607.62354515, 166567.26007785,\n",
       "        190258.4392123 , 182206.80724157, 175948.24123675,\n",
       "        216907.53673036, 196996.64588771, 177039.03852873,\n",
       "        169443.55624169, 168204.16934568, 168769.12769733,\n",
       "        187091.09069907, 178680.5026416 , 184910.88994378,\n",
       "        184047.95504441, 178570.25834797, 182274.95447084,\n",
       "        193651.26147671, 198567.95253814, 188601.65141426,\n",
       "        196977.10248887, 183540.97656812, 189844.22328132,\n",
       "        191968.12394364, 194801.79525174, 167653.16300955,\n",
       "        174002.61946904, 185157.0331488 , 169424.54519654,\n",
       "        160410.23942894, 194101.0087441 , 166110.87364157,\n",
       "        200903.92473307, 207092.71361383, 172159.56101435,\n",
       "        181379.75762107, 160617.2839018 , 168166.31820238,\n",
       "        184337.66556404, 193447.42337738, 189597.98759128,\n",
       "        191543.54527412, 187131.07175564, 201014.53739242,\n",
       "        177514.81395433, 207647.97562864, 192738.85645381,\n",
       "        152755.54048767, 176751.29864979, 169729.64813204,\n",
       "        192429.67275843, 192202.24525824, 184574.37501334,\n",
       "        199538.2750866 , 181173.18840028, 178198.34612939,\n",
       "        190397.83248746, 182204.95741932, 177085.48438883,\n",
       "        160267.39743009, 183101.11498458, 160375.93013821,\n",
       "        195088.6596432 , 181843.24866639, 184408.95564324,\n",
       "        158510.38215364, 187199.11137757, 171677.07189471,\n",
       "        171903.01147835, 207387.98141169, 184495.04246892,\n",
       "        169869.32209307, 194367.05055685, 180160.2581071 ,\n",
       "        176936.32196285, 198784.55411438, 180446.24924605,\n",
       "        191093.8361153 , 201610.30603391, 181796.1218291 ,\n",
       "        170331.9677442 , 180997.30226878, 241722.1878625 ,\n",
       "        182612.86853437, 169692.94317902, 150824.49348277,\n",
       "        185807.17616313, 180304.22691016, 172980.91601904,\n",
       "        179506.8098559 , 186419.66237289, 191994.98200076,\n",
       "        155797.67737968, 187201.87577112, 197040.35749316,\n",
       "        195480.74771221, 182657.05591974, 195134.35178844,\n",
       "        194801.94648108, 193990.78654316, 189555.62658373,\n",
       "        161399.71836455, 185741.45939586, 177318.75161645,\n",
       "        208285.86762441, 175314.31835371, 183929.51930833,\n",
       "        197879.3462701 , 191210.46706178, 168656.93035609,\n",
       "        190840.40984439, 167733.06398682, 205924.79845346,\n",
       "        179128.2275051 , 189964.33651613, 184109.34222812,\n",
       "        182827.99485767, 174618.74264584, 188153.34938823,\n",
       "        173181.53618328, 169750.71904361, 177010.0070155 ,\n",
       "        177690.81614916, 161361.15398934, 182575.70277518,\n",
       "        203131.2737954 , 198118.51447932, 169580.07157323,\n",
       "        188657.53652116, 178219.88320952, 152582.56257013,\n",
       "        154166.21522495, 200220.86684963, 198683.49426253,\n",
       "        205113.02103009, 185268.93201787, 148703.89502725,\n",
       "        178870.43036229, 186127.7481857 , 139753.1377189 ,\n",
       "        143331.17894071, 190975.69031051, 200759.65718633,\n",
       "        188985.3875471 , 208102.89251644, 178743.48036   ,\n",
       "        146328.47645638, 192419.64220187, 182365.34116195,\n",
       "        176258.53674398, 167922.14742198, 187267.56078375,\n",
       "        208267.1495574 , 198361.24433989, 184976.55080282,\n",
       "        169992.75779494, 174054.75864747, 141848.43833979,\n",
       "        186192.98132331, 145483.54744708, 170271.27901573,\n",
       "        191959.01820677, 176344.24390506, 162804.64268369,\n",
       "        167358.78916182, 116547.92751785, 180685.98604189,\n",
       "        181286.61455774, 178037.1432155 , 194896.95322839,\n",
       "        197986.78526078, 182161.60983352, 171540.32329973,\n",
       "        174150.45531198, 186343.28077758, 187014.78096626,\n",
       "        179254.22194846, 196138.02186409, 192663.73574804,\n",
       "        142204.92803817, 204592.58426729, 192381.41398374,\n",
       "        184541.06085894, 152832.6177233 , 193368.45359119,\n",
       "        222797.48820107, 235362.55332386, 197567.9864996 ,\n",
       "        181427.8510938 , 183061.7134659 , 149626.0046505 ,\n",
       "        202052.64333171, 199784.11496024, 207570.34161682,\n",
       "        166180.26865945, 190515.0666204 , 183394.54260358,\n",
       "        178024.10828717, 185635.23233657, 174023.2335541 ,\n",
       "        172319.05968298, 170978.58376004, 188369.71517885,\n",
       "        192290.70402933, 182907.32870366, 188962.91998839,\n",
       "        183232.44262085, 171185.21301767, 199194.57692459,\n",
       "        182220.08107335, 182284.82116539, 178117.77339423,\n",
       "        186716.16349987, 188068.51416079, 187885.00128783,\n",
       "        210646.76407121, 193965.11729762, 147324.81385365,\n",
       "        174237.67400353, 198000.73479294, 159053.3092096 ,\n",
       "        176121.20046819, 191914.75264728, 188779.97390543,\n",
       "        179279.96547096, 187700.07299654, 183080.75676071,\n",
       "        179396.34627228, 178767.77988027, 195038.03711504,\n",
       "        190940.27271947, 197307.86142017, 169849.5555595 ,\n",
       "        182531.18304346, 193054.15296713, 185950.8096877 ,\n",
       "        181006.72852852, 137986.70513945, 190961.25227702,\n",
       "        188275.32325651, 199737.43087433, 183969.31044649,\n",
       "        177580.874737  , 205586.89443029, 160296.56165102,\n",
       "        175556.67308471, 191029.5293081 , 153335.34013443,\n",
       "        189626.88152218, 173817.1744469 , 210211.4271799 ,\n",
       "        190156.4504364 , 187234.16622668, 170883.15836673,\n",
       "        200366.29017522, 191188.89669601, 164234.52554037,\n",
       "        174104.24022298, 204347.81724812, 194549.87547312,\n",
       "        171528.4970487 , 176552.73762217, 167788.54233909,\n",
       "        185636.89797408, 180275.3171672 , 180081.05084601,\n",
       "        189440.78555377, 198855.99647407, 184298.33040104,\n",
       "        187568.464005  , 189097.6759661 , 181547.78914426,\n",
       "        187628.55384972, 181048.98733689, 142559.3994683 ,\n",
       "        172412.35802577, 166055.56363769, 187722.81986551,\n",
       "        202952.02522956, 167935.57708949, 142416.96364646,\n",
       "        185122.4722689 , 195517.70954649, 215005.47137424,\n",
       "        197254.93779785, 192219.32069424, 209099.55091769,\n",
       "        197795.70362471, 202098.25032775, 192711.08182741,\n",
       "        186881.18747382, 152005.12515682]])"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbd90f23c18>"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(2000), Sc.loss, linewidth=4, color=\"red\", label=\"loss\")\n",
    "plt.plot(range(2000), Sc.val_loss, linewidth=4, color=\"blue\", label=\"val_loss\")\n",
    "plt.ylabel(\"loss_fnc\")\n",
    "plt.xlabel(\"lr\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題8】（アドバンス課題）バイアス項の除去\n",
    "バイアス項 \n",
    "θ\n",
    "0\n",
    " を抜くと学習がどう変化するか検証してください。また、線形回帰モデルにおけるバイアス項の役割の考察・調査を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.45676997e+10 1.41082134e+10 1.36653091e+10 ... 1.83534280e+09\n",
      " 1.83534280e+09 1.83534280e+09]\n",
      "[4.78579303e+09 4.63793901e+09 4.49539862e+09 ... 6.55071552e+08\n",
      " 6.55071552e+08 6.55071552e+08]\n"
     ]
    }
   ],
   "source": [
    "Sc = ScratchLinearRegression(num_iter=2000, lr=0.000001, bias=False, verbose=True)\n",
    "Sc.fit(X = X_train, y = y_train, X_val=X_test, y_val=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45676997e+10, 1.41082134e+10, 1.36653091e+10, ...,\n",
       "       1.83534280e+09, 1.83534280e+09, 1.83534280e+09])"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.78579303e+09, 4.63793901e+09, 4.49539862e+09, ...,\n",
       "       6.55071552e+08, 6.55071552e+08, 6.55071552e+08])"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sc.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbdd103be10>"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(2000), Sc.loss, linewidth=4, color=\"red\", label=\"loss\")\n",
    "plt.plot(range(2000), Sc.val_loss, linewidth=4, color=\"blue\", label=\"val_loss\")\n",
    "plt.ylabel(\"loss_fnc\")\n",
    "plt.xlabel(\"lr\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
